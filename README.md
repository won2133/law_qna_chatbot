# 법률 질의응답 챗봇
## 개요
* RAG 기반 생성형 챗봇
  * 입력된 질문과 가장 유사한 데이터로부터 답변을 생성하여 반환
  * 검색 방법은 의미 검색과 키워드 검색을 섞은 하이브리드 검색 방법 사용
## 데이터
* 법률과 관련된 질문과 그에 대한 답변이 있는 데이터
  * Ai 허브의 '법률-규정 텍스트 분석 데이터_고도화_상황에 따른 판례 데이터'를 사용했다.
    * Training 폴더와 Validation 폴더에서 입력된 질문과 유사도를 검사할 때 사용할 질문(question)과 질문에 대한 응답으로 보여줄 판례 내용의 요약본(summ_pass)을 추출하였다.
    * other 폴더에서 질문과 응답을 추출하여 위 데이터와 합쳐서 csv 형태로 저장하였다. (8만 4천 여개)
  * 챗봇을 완성시킨 후 법률구조공단의 질의응답 데이터를 마지막에 추가해주었다. 
    * 법률 구조 공단의 경우 질문을 간소화하여 제목으로 사용하고 있어서 질문-응답 쌍과 제목-응답 쌍을 따로 저장. (만 팔천 여개)
* 임베딩을 하기 위해 모델을 학습시킬 데이터
  * ai 허브의 대규모 구매도서 기반 한국어 말뭉치 데이터의 법률, 법학(TL360) 폴더의 데이터를 사용했다.
* rag를 구현하기 위해 질문과 context, 그에 따른 답변이 있는 데이터
  * 한국어로 된 법률과 관련된 데이터를 찾지 못해 일반적인 내용의 'jaeyong2/RAG-COT-Ko'(허깅페이스)를 사용하였다.
  * context와 질문, 응답 순으로 입력 받고 스페셜 토큰으로 구분하도록 프롬프트를 만든 뒤 text 열에 저장하였다. text의 길이가 1024 미만인 것만 필터링한 후 사용하였다.(19만 2천여 개)
## 유사도의 정확성 높이기
### 1. 형태소 분석기 선택
* 정확도를 높이기 위해 여러 가시 형태소 분석기와 임베딩 모델 등을 비교하였다.
  * 각 모델과 기법들을 비교하기 위해서, 수집한 데이터 중 하나를 답변으로 하는 또다른 질문과 답변 쌍이 필요했다. 
  * 그래서 질문을 역번역하여 새로운 질문과 응답쌍을 만들고 이 중 만 개의 샘플을 뽑아 비교하는 데 사용했다.
  * 결과로 출력된 다섯 개의 요약본 중 정답이 있는 것의 비율을율 비교했다.
* 형태소 분석기는 kiwi, okt, hannanum, komoran, kkma를 비교했다. w2v를 이용하여 임베딩하고 코사인 유사도를 이용하여 유사도를 측정하였다.
  <pre><code>* 가장 높게 나온 kkma 선택
  kiwi: 0.6016
  okt: 0.4569
  hannm: 0.3047
  komoran: 0.4299
  <b>kkma: 0.6211</b>
  </code></pre>
### 2. 불용어 정의
* 앞서 형태소 분석기를 비교할 때 임의로 몇 개의 불용어를 정해 진행하였는데, 이것과 지정하지 않은 것, 그리고 가장 빈도수가 높은 상위 50개의 단어를 불용어로 하는 것 등의의 세 가지를 비교하였다.
  * 상위 50개 단어는 다음과 같이 대부분 조사나 어미였는데, 계약이라는 단어가 있어서 이는 제외하고 나머지 전체를 불용어로 지정하였다.
    <pre><code>['하', '의', '에', '이', '는', '을', '가', '되', '를', '있', '여', '으로', '계약', '경우', '는가', '수', '아', '로', '그', '은', '고', '제', '것', '지', '에서', '저', '대하', '조', '어', '등', '행위', '관하', '해당', '보', '항', '에게', '및', '과', '받', '와', '없', '의하', '다고', '처분', '않', '또는', '였', '었', '나요', '따르']
    </code></pre>
  <pre><code>* 가장 높은 최빈값을 불용어로 지정
  <b>최빈값: 0.6770</b>
  불용어X: 0.6452
  기존: 0.6211
  </code></pre>
### 3. 임베딩 모델 선택
* sbert와 fasttext, word2vec를 비교했다. sbert는  "snunlp/KR-SBERT-V40K-klueNLI-augSTS" 를를 사용하였고, 이었고, fasttext와 word2vec는 앞서 설명한 책 데이터를 이용해 학습한 뒤 사용하였다.
  <pre><code>* sbert 선택
  <b>sbert: 0.7372</b>
  w2v: 0.6770
  fst: 0.6119
  </code></pre>
### 4. 검색 방법 선택
* 우선 유사도 기반의 의미 검색 방법에서 사용할 유사도 측정 방법을 결정하기 위해 코사인 유사도, 피어슨 유사도, 유클리드 유사도를 비교하였다.
  * 만 개로 했을 때 코사인과 피어슨 유사도 결과가 너무 유사하게 나와서 샘플을 25000개로 늘리고 다시 비교했다.
    <pre><code>*코사인 선택
     <b>코사인: 0.7372
    (25000개:  0.74036)</b>
    피어슨: 0.7373
    (25000개: 0.7344)
    유클리드: 0.7286
    </code></pre>
* 코사인 유사도를 이용한 의미 검색 방법만 사용했을 때와 키워드 기반 방식 중 하나인 BM25를 하이브리드로 사용했을 때의 결과를 비교하였다.
  * 키워드 검색의 토크나이저는 "klue/roberta-base" 사용 
  <pre><code>*하이브리드 검색 선택
   의미 검색만: 0.7372
   <b>하이브리드 검색: 0.8445</b>
  </code></pre>
## RAG 기반 챗봇 구현
### 1. 모델
* "EleutherAI/polyglot-ko-1.3b" 사용, 1에포크 학습
  * 토크나이저도 동일 토크나이저 사용
### 2. 학습 및 추론
* 프롬프트에 사용된 토큰 중 기존 토크나이저에 없었던 질문 토큰, 답변 토큰, context 토큰을 스페셜 토큰으로 만들어서 토크나이저에 추가하였다.
* 아래 gpt 챗봇 만드는 코드를 이용해서 직접 파이프라인 만들고 추론하였다. 
  * 문장이 반복되는 경향이 있어서 문장 구분 토큰이나 종료 토큰이 나오면 중단하도록 하여 하나의 문장만 출력하였다.
  * 예시
    <pre><code>입력: &lt;context&gt;토지에 대하여 도로로서의 도시계획시설결정 및 지적승인만 있었을 뿐 그 도시계획사업이 실시되었거나 그 토지가 자연공로로 이용된 적이 없는 경우에는 도시계획결정 및 지적승인의 고시만으로는 아직 공용개시행위가 있었다고 할 수 없어 그 토지가 행정재산이 되었다고 할 수 없다.<|sep|> &ltquestion&gt도로가 행정재산이 되기 위한 요건 및 토지에 대하여 도로로서의 도시계획시설결정 및 지적승인이 있다는 사정만으로 그 토지가 행정재산이 되는가?<|sep|> &ltsys&gt
  
    결과: 토지에 대하여 도로로서의 도시계획시설결정 및 지적승인이 있다는 사정만으로는 아직 공용개시행위가 있었다고 할 수 없어 그 토지가 행정재산이 되지 않는다.</code></pre>
### 3. 하이브리드 검색
* 저장해둔 데이터 중 입력된 쿼리와 가장 유사한 것을 찾기 위해 의미 검색과 키워드 검색을 합친 하이브리드 검색을 사용하였다.
* faiss의 IndexFlatL2 클래스를 이용하여 KNN 검색 인덱스를 생성하고 임베딩을 저장하여 의미 검색에 사용하였고 키워드 검색 중 하나인 BM25를 구현하였다.
  * 아래 서적의 코드를 그대로 사용하였다. 단, 데이터의 규모가 크지 않다고 판단해 유사도가 일정 수준 이하이면 관련된 문서를 찾지 못했다고 출력하도록 수정하였다.
* 예시
  <pre><code>입력된 질문: 이혼한 후에 자녀의 성과 본을 바꿀 수 있나요?

  가장 유사하다고 나온 질문: 부부가 이혼하는 경우 자녀의 복리를 위하여 자의 성과 본을 변경할 수 있나요?

  위의 질문에 해당하는 답변과 입력된 질문으로 생성된 프롬프트: &ltcontext&gt네.<|sep|>  자의 복리를 위하여 필요한 경우 법원의 허가를 얻어 자의 성과 본을 변경할 수 있습니다.<|sep|> &ltquestion&gt이혼한 후에 자녀의 성과 본을 바꿀 수 있나요?<|sep|> &ltsys&gt

  결과: 이혼한 후에 자녀의 성과 본을 바꿀 수 있습니다.
  </code></pre>
## 파일 설명
### data
* pan_qna.py: 판례 데이터 중에서 질의(question)응답(summ_pass)만 저장
* scraping.ipynb: 법률구조공단 사이트에서 상담(질의응답)을 스크래핑하여 토큰화 및 임베딩을 마치고 저장
* book_law.py: 도서 데이터 중에서 법률 부분만 저장
### validation
* tokenizing_n_embedding.ipynb: 각 형태소 분석기 별로 토큰화하고 불용어를 정의하고 각 임베딩 모델로 임베딩
* back_translation.ipynb: 질문을 역번역하고 샘플 만 개를 뽑아 저장
* check_similarity_chatbot_result.ipynb: 역번역 질문을 이용하여 정답을 맞힌 개수를 확인. 각 단계 별로 후보들을 비교
### chatbot
* polyglot-ko-1.3b-RAG-COT-ko.ipynb: 데이터 불러오고 학습
* polyglot-ko-1.3b-RAG-COT-ko_pipeline.ipynb: 추론, 하이브리드 검색 적용

## 참고 목록
* <딥 러닝을 이용한 자연어 처리 입문> Bryce,Eddie 저 (https://wikidocs.net/book/2155) :  토큰화, 임베딩, sbert를 이용한 한국어 챗봇 등 유사도 계산을 위한 과정의 대부분 
* <LLM을 활용한 실전 AI 애플리케이션 개발> 허정준 저 : sLLM 학습, 하이브리드 검색 등 RAG 구현의의 대부분
* <Pytorch 딥러닝 챗봇> 권경혁 저 : kogpt2 챗봇(https://wikidocs.net/158023) - 파이프라인 생성에 활용
